# --- QUY TRÃŒNH Tá»° Äá»˜NG HÃ“A CUá»I CÃ™NG - PHIÃŠN Báº¢N NÃ‚NG Cáº¤P V4 ---
# TÃªn file: .github/workflows/scrape.yml

name: 'TopCV Daily Scraper'

on:
  # Cháº¡y tá»± Ä‘á»™ng vÃ o 7 giá» sÃ¡ng má»—i ngÃ y (giá» Viá»‡t Nam)
  schedule:
    - cron: '0 0 * * *' # Ná»­a Ä‘Ãªm giá» UTC (7h sÃ¡ng giá» VN)
  # Cho phÃ©p cháº¡y thá»§ cÃ´ng tá»« tab Actions trÃªn GitHub
  workflow_dispatch:

jobs:
  # --- GIAI ÄOáº N 1: TRINH SÃT ---
  discover:
    runs-on: ubuntu-latest
    outputs:
      # Xuáº¥t ra tá»•ng sá»‘ trang Ä‘á»ƒ cÃ¡c job sau cÃ³ thá»ƒ sá»­ dá»¥ng
      totalPages: ${{ steps.get_pages.outputs.count }}
    steps:
      - name: 'Checkout repository'
        uses: actions/checkout@v4
      - name: 'Set up Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      - name: 'Install dependencies for scout'
        run: npm install puppeteer-extra puppeteer-extra-plugin-stealth
      - name: 'Run scout script to get total pages'
        id: get_pages
        # Cháº¡y script trinh sÃ¡t vÃ  lÆ°u káº¿t quáº£ vÃ o output
        run: echo "count=$(node discover_pages.js)" >> $GITHUB_OUTPUT

  # --- GIAI ÄOáº N 2: KHAI THÃC SONG SONG ---
  collect:
    # Cáº§n job 'discover' hoÃ n thÃ nh trÆ°á»›c
    needs: discover
    runs-on: ubuntu-latest
    strategy:
      # Cháº¡y song song, náº¿u má»™t worker lá»—i, cÃ¡c worker khÃ¡c váº«n tiáº¿p tá»¥c
      fail-fast: false
      matrix:
        # Triá»ƒn khai 15 "cÃ´ng nhÃ¢n", báº¡n cÃ³ thá»ƒ tÄƒng/giáº£m náº¿u cáº§n
        worker: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] 
    steps:
      - name: 'Checkout repository'
        uses: actions/checkout@v4
      - name: 'Set up Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      - name: 'Install all project dependencies'
        run: npm install
      
      - name: 'Run collection worker'
        env:
          PROXY_API_KEY: ${{ secrets.PROXY_API_KEY }}
        run: |
          PAGES_PER_WORKER=10
          TOTAL_PAGES=${{ needs.discover.outputs.totalPages }}
          WORKER_INDEX=${{ matrix.worker }}
          
          START_PAGE=$(( (WORKER_INDEX - 1) * PAGES_PER_WORKER + 1 ))
          END_PAGE=$(( WORKER_INDEX * PAGES_PER_WORKER ))
          
          if (( END_PAGE > TOTAL_PAGES )); then
            END_PAGE=$TOTAL_PAGES
          fi
          
          if (( START_PAGE <= TOTAL_PAGES )); then
            node collector.js "ke-toan" $START_PAGE $END_PAGE $WORKER_INDEX
          else
            echo "Worker ${{ matrix.worker }} khÃ´ng cáº§n cháº¡y."
          fi
      
      - name: 'Upload worker artifact'
        # NÃ‚NG Cáº¤P LÃŠN V4
        uses: actions/upload-artifact@v4
        with:
          name: raw-results-${{ matrix.worker }}
          path: results_worker_${{ matrix.worker }}.csv
          if-no-files-found: ignore

  # --- GIAI ÄOáº N 3: Tá»”NG Há»¢P VÃ€ LÆ¯U TRá»® ---
  combine-and-commit:
    needs: collect
    runs-on: ubuntu-latest
    steps:
      - name: 'Checkout repository'
        uses: actions/checkout@v4
      - name: 'Set up Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      - name: 'Download all worker artifacts'
        # NÃ‚NG Cáº¤P LÃŠN V4
        uses: actions/download-artifact@v4
        with:
          path: ./raw-results
      - name: 'Install dependencies for combination script'
        run: npm install csv-parse csv-stringify
      - name: 'Combine results and check for duplicates'
        id: combine
        run: |
          node -e "
            const fs = require('fs');
            const path = require('path');
            const { parse } = require('csv-parse/sync');
            const { stringify } = require('csv-stringify/sync');

            const artifactsDir = './raw-results';
            const allJobs = new Map();

            if (fs.existsSync(artifactsDir)) {
              const workerDirs = fs.readdirSync(artifactsDir);
              for (const dir of workerDirs) {
                try {
                  const files = fs.readdirSync(path.join(artifactsDir, dir));
                  for (const file of files) {
                    if (file.endsWith('.csv')) {
                      try {
                        const content = fs.readFileSync(path.join(artifactsDir, dir, file), 'utf-8');
                        const records = parse(content, { columns: true, skip_empty_lines: true });
                        records.forEach(record => {
                          if (record.link) {
                            allJobs.set(record.link, record);
                          }
                        });
                      } catch (e) {
                        console.log(`Bá» qua file lá»—i: ${file}`);
                      }
                    }
                  }
                } catch(e) {
                   console.log(`Bá» qua thÆ° má»¥c lá»—i: ${dir}`);
                }
              }
            }
            
            if (allJobs.size > 0) {
              const finalData = Array.from(allJobs.values());
              const date = new Date().toLocaleDateString('vi-VN', {year: 'numeric', month: '2-digit', day: '2-digit', timeZone: 'Asia/Ho_Chi_Minh'}).replace(/\//g, '-');
              const finalFilename = \`data/topcv_ketoan_\${date}.csv\`;
              
              fs.mkdirSync('data', { recursive: true });
              fs.writeFileSync(finalFilename, '\ufeff' + stringify(finalData, { header: true }));
              console.log(`ÄÃ£ tá»•ng há»£p \${finalData.length} tin duy nháº¥t vÃ o \${finalFilename}`);
              
              // Sá»­ dá»¥ng cÃº phÃ¡p má»›i Ä‘á»ƒ set output
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `final_filename=${finalFilename}\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `jobs_count=${finalData.length}\n`);
            } else {
              console.log('KhÃ´ng cÃ³ dá»¯ liá»‡u má»›i Ä‘á»ƒ tá»•ng há»£p.');
              fs.appendFileSync(process.env.GITHUB_OUTPUT, 'jobs_count=0\n');
            }
          "
      - name: 'Commit results to repository'
        if: steps.combine.outputs.jobs_count > 0
        run: |
          git config --global user.name 'GitHub Actions Scraper'
          git config --global user.email 'actions@github.com'
          git add ${{ steps.combine.outputs.final_filename }}
          git commit -m "ðŸ“Š Dá»¯ liá»‡u TopCV: ThÃªm ${{ steps.combine.outputs.jobs_count }} tin má»›i vÃ o ${{ steps.combine.outputs.final_filename }}"
          git push